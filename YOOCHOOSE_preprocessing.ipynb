{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd360bfb",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c9ddbf",
   "metadata": {},
   "source": [
    "# Chosen Dataset: <u> YOOCHOOSE - RecSys Challenge 2015</u> \n",
    "<u>general explaination on the dataset:</u><br>\n",
    "The YOOCHOOSE dataset contain a collection of sessions from a retailer, where each session<br>\n",
    "is encapsulating the click events that the user performed in the session.<br>\n",
    "For some of the sessions, there are also buy events; means that the session ended with the user bought something from the web shop.<br> The data was collected during several\n",
    "months in the year of 2014, reflecting the clicks and purchases performed by the users of an on-line retailer in Europe.<br>\n",
    "**We thus conclude that the dataset represents an implicit recommender system challange due to a binary representations of the data - clicked or not, bought or not.**<br>\n",
    "The dataset is composed out of 3 files (and a readme as well):\n",
    " - yoochoose-buys.dat , ~55MB\n",
    " - yoochoose-clicks.dat, ~1.5GB\n",
    " - yoochoose-test.dat,  ~363 MB\n",
    " \n",
    "<br>**The authors of the original paper ignored the testset and just splitted yoochoose-clicks.dat into train and test datasets.\n",
    "in order to maintain consistency and to try and recreate the authors results, we will do the same**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d7cdd",
   "metadata": {},
   "source": [
    "#### <u>CLICKS DATASET FILE DESCRIPTION</u>\n",
    "\n",
    "The file yoochoose-clicks.dat comprising the clicks of the users over the items.<br>\n",
    "Each record/line in the file has the following fields/format: Session ID, Timestamp, Item ID, Category<br>\n",
    "-Session ID – the id of the session. In one session there are one or many clicks. Could be represented as an integer number.<br>\n",
    "-Timestamp – the time when the click occurred. Format of YYYY-MM-DDThh:mm:ss.SSSZ<br>\n",
    "-Item ID – the unique identifier of the item that has been clicked. Could be represented as an integer number.<br>\n",
    "-Category – the context of the click. The value \"S\" indicates a special offer, \"0\" indicates  a missing value, a number between 1 to 12 indicates a real category identifier,<br>\n",
    " any other number indicates a brand. E.g. if an item has been clicked in the context of a promotion or special offer then the value will be \"S\", if the context was a brand i.e BOSCH,<br>\n",
    " then the value will be an 8-10 digits number. If the item has been clicked under regular category, i.e. sport, then the value will be a number between 1 to 12. <br>\n",
    " \n",
    "* The explanation above is based on the README.txt attached to the dataset.<br>\n",
    "    This dataset is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0\n",
    "    International License. To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-nd/4.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fca9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8111570",
   "metadata": {},
   "source": [
    "## Data Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9df18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clicks_df = pd.read_csv('data/yoochoose-clicks.dat',names=['SessionID','Time', 'ItemID']\n",
    "                        ,usecols=[0,1,2],\n",
    "                        dtype={0:np.int32, 1:str, 2:np.int64})\n",
    "# convert date into timestamp:\n",
    "clicks_df['Time'] = clicks_df['Time'].apply(lambda x: dt.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ').timestamp()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3674d4",
   "metadata": {},
   "source": [
    "filter out sessions of only 1 interaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd023163",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_lengths = clicks_df.groupby('SessionID').size()\n",
    "clicks_df = clicks_df[np.in1d(clicks_df['SessionID'], session_lengths[session_lengths>1].index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6494f7",
   "metadata": {},
   "source": [
    "filter out items rarely bought items and leave only items which have been purchased 5 times or more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfbdcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_supports = clicks_df.groupby('ItemID').size()\n",
    "clicks_df = clicks_df[np.in1d(clicks_df['ItemID'], item_supports[item_supports>=5].index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa14e2c",
   "metadata": {},
   "source": [
    "re - filter out sessions of only 1 interaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_lengths = clicks_df.groupby('SessionID').size()\n",
    "clicks_df = clicks_df[np.in1d(clicks_df['SessionID'], session_lengths[session_lengths>1].index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e00b85d",
   "metadata": {},
   "source": [
    "### Train - Test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b98c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax = clicks_df['Time'].max()\n",
    "day  = 86400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5391b67",
   "metadata": {},
   "source": [
    "Split the dataset into\n",
    "- test: last day of sessions\n",
    "- train: all days of sessions except last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4642b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_max_times = clicks_df.groupby('SessionID')['Time'].max()\n",
    "session_train = session_max_times[session_max_times < tmax-day].index\n",
    "session_test = session_max_times[session_max_times >= tmax-day].index\n",
    "train = clicks_df[np.in1d(clicks_df['SessionID'], session_train)]\n",
    "test = clicks_df[np.in1d(clicks_df['SessionID'], session_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d15b5",
   "metadata": {},
   "source": [
    "filter out clicks from the test set where the items are not in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d8c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[np.in1d(test['ItemID'], train['ItemID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbccf7d4",
   "metadata": {},
   "source": [
    "if by any chance there are sessions in test set which has less than 2 sessions - filter them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e7ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tslength = test.groupby('SessionID').size()\n",
    "test = test[np.in1d(test['SessionID'], tslength[tslength>=2].index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de0df6d",
   "metadata": {},
   "source": [
    "#### Final train and test files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaca253",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Full train set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(train), train['SessionID'].nunique(), train['ItemID'].nunique()))\n",
    "print('Test set set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(test), test['SessionID'].nunique(), test['ItemID'].nunique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the files:\n",
    "train.to_csv('data/train.txt', sep='\\t', index=False)\n",
    "test.to_csv('data/test.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1962bc2a",
   "metadata": {},
   "source": [
    "### Creating validation set of training set\n",
    "same mechanism as splitting clicks dataframe into train and test - last day of sessions is converted to validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6866eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax = train['Time'].max()\n",
    "session_max_times = train.groupby('SessionID')['Time'].max()\n",
    "session_train = session_max_times[session_max_times < tmax-day].index\n",
    "session_valid = session_max_times[session_max_times >= tmax-day].index\n",
    "train_tr = train[np.in1d(train['SessionID'], session_train)]\n",
    "valid = train[np.in1d(train['SessionID'], session_valid)]\n",
    "valid = valid[np.in1d(valid['ItemID'], train_tr['ItemID'])]\n",
    "tslength = valid.groupby('SessionID').size()\n",
    "valid = valid[np.in1d(valid['SessionID'],tslength[tslength>=2].index)]\n",
    "#Convert To CSV\n",
    "print('Train set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(train_tr), train_tr['SessionID'].nunique(), train_tr['ItemID'].nunique()))\n",
    "train_tr.to_csv('data/train_tr.txt', sep=',', index=False)\n",
    "print('Validation set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(valid), valid['SessionID'].nunique(), valid['ItemID'].nunique()))\n",
    "valid.to_csv('data/train_valid.txt', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5223e4d2",
   "metadata": {},
   "source": [
    "### Smaller Sample: 4.5 days of sessions,\n",
    "#### Train - Test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(test) / len(train))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9fbc51",
   "metadata": {},
   "source": [
    "In the original paper, the author used a really small portion of data for test set.\n",
    "we will try to remain around higher precentage of split to test and validation because our sample is alot smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9759b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = clicks_df['Time'].min()\n",
    "day  = 86400\n",
    "tmax = tmin +day*4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf8946",
   "metadata": {},
   "source": [
    "Split the dataset into\n",
    "- test: last day of sessions\n",
    "- train: all days of sessions except last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed56e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_df = clicks_df[clicks_df['Time'] <= tmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f0abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_max_times = clicks_df.groupby('SessionID')['Time'].max()\n",
    "session_train = session_max_times[session_max_times < tmax-day*0.5].index\n",
    "session_test = session_max_times[session_max_times >= tmax-day*0.5].index\n",
    "train_samp = clicks_df[np.in1d(clicks_df['SessionID'], session_train)]\n",
    "test_samp = clicks_df[np.in1d(clicks_df['SessionID'], session_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c09542",
   "metadata": {},
   "source": [
    "filter out clicks from the test set where the items are not in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1117f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samp = test_samp[np.in1d(test_samp['ItemID'], train_samp['ItemID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d22c0b",
   "metadata": {},
   "source": [
    "if by any chance there are sessions in test set which has less than 2 sessions - filter them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2febc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tslength = test_samp.groupby('SessionID').size()\n",
    "test_samp = test_samp[np.in1d(test_samp['SessionID'], tslength[tslength>=2].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sampled train set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(train_samp), train_samp['SessionID'].nunique(), train_samp['ItemID'].nunique()))\n",
    "print('Sampled Test set set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(test_samp), test_samp['SessionID'].nunique(), test_samp['ItemID'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c60b5d",
   "metadata": {},
   "source": [
    "### Creating validation set of training set\n",
    "same mechanism as splitting clicks dataframe into train and test - last day of sessions is converted to validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76477f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax = train_samp['Time'].max()\n",
    "session_max_times = train_samp.groupby('SessionID')['Time'].max()\n",
    "session_train_samp = session_max_times[session_max_times < tmax-day*0.5].index\n",
    "session_valid = session_max_times[session_max_times >= tmax-day*0.5].index\n",
    "train_samp_tr = train_samp[np.in1d(train_samp['SessionID'], session_train_samp)]\n",
    "valid = train_samp[np.in1d(train_samp['SessionID'], session_valid)]\n",
    "valid = valid[np.in1d(valid['ItemID'], train_samp_tr['ItemID'])]\n",
    "tslength = valid.groupby('SessionID').size()\n",
    "valid = valid[np.in1d(valid['SessionID'],tslength[tslength>=2].index)]\n",
    "#Convert To CSV\n",
    "print('train_samp set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(train_samp_tr), train_samp_tr['SessionID'].nunique(), train_samp_tr['ItemID'].nunique()))\n",
    "train_samp_tr.to_csv('data/train_samp_tr.txt', sep=',', index=False)\n",
    "print('Validation set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(valid), valid['SessionID'].nunique(), valid['ItemID'].nunique()))\n",
    "valid.to_csv('data/train_samp_valid.txt', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35876087",
   "metadata": {},
   "source": [
    "filter out clicks from the test set where the items are not in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7438efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samp = test_samp[np.in1d(test_samp['ItemID'], train_samp_tr['ItemID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07074be3",
   "metadata": {},
   "source": [
    "if by any chance there are sessions in test set which has less than 2 sessions - filter them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeaa020",
   "metadata": {},
   "outputs": [],
   "source": [
    "tslength = test_samp.groupby('SessionID').size()\n",
    "test_samp = test_samp[np.in1d(test_samp['SessionID'], tslength[tslength>=2].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee09a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sampled Test set set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(test_samp), test_samp['SessionID'].nunique(), test_samp['ItemID'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af02fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samp.to_csv('data/test_samp.txt', sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
